{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HTTP\n",
    "\n",
    "# フォルダ「data」が存在しない場合は作成する\n",
    "data_dir = \"./data/\"\n",
    "if !isdir(data_dir)\n",
    "    mkdir(data_dir)\n",
    "end\n",
    "\n",
    "# ImageNetのclass_indexをダウンロードする\n",
    "## Kerasで用意されているものを利用\n",
    "## https://github.com/fchollet/deep-learning-models/blob/master/imagenet_utils.py\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "save_path = joinpath(data_dir, \"imagenet_class_index.json\")\n",
    "\n",
    "if !isfile(save_path)\n",
    "    HTTP.open(:GET, url) do http\n",
    "        open(save_path, \"w\") do file\n",
    "            write(file, http)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant zip. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport zipfile\n",
    "\n",
    "# アリとハチの画像データをダウンロードし解凍\n",
    "## PyTorchのチュートリアルで用意されているものを利用\n",
    "## https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "save_path = joinpath(data_dir, \"hymenoptera_data.zip\")\n",
    "\n",
    "if !isfile(save_path)\n",
    "    HTTP.open(:GET, url) do http\n",
    "        open(save_path, \"w\") do file\n",
    "            write(file, http)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # ZIPファイルを読み込み\n",
    "    const zip = zipfile.ZipFile(save_path)\n",
    "    zip.extractall(data_dir)  # ZIPを解凍\n",
    "    zip.close()  # ZIPファイルをクローズ\n",
    "\n",
    "    # ZIPファイルを消去\n",
    "    rm(save_path)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要パッケージのimport\n",
    "@pyimport numpy as np\n",
    "@pyimport json\n",
    "@pyimport PIL.Image as Image\n",
    "@pyimport matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch関連パッケージのimport\n",
    "@pyimport torch\n",
    "@pyimport torchvision\n",
    "@pyimport torchvision.models as models\n",
    "@pyimport torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.7.1\n",
      "Torchvision Version: 0.8.2\n"
     ]
    }
   ],
   "source": [
    "# PyTorchのバージョン確認\n",
    "println(\"PyTorch Version: \", torch.__version__)\n",
    "println(\"Torchvision Version: \", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/user/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|███████████████████████████████████████| 528M/528M [00:09<00:00, 59.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyObject VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 学習済みのVGG-16モデルをロード\n",
    "# 初めて実行する際は、学習済みパラメータをダウンロードするため、実行に時間がかかります\n",
    "\n",
    "# VGG-16モデルのインスタンスを生成\n",
    "use_pretrained = true  # 学習済みのパラメータを使用\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "net.eval()  # 推論モードに設定\n",
    "\n",
    "# モデルのネットワーク構成を出力\n",
    "println(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
